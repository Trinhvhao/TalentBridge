import sqlite3
import json
import logging
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.documents import Document
from typing import List, Tuple
import os
from dotenv import load_dotenv
from chroma_utils import get_vectorstore
import asyncio
from contextlib import contextmanager
import re

# ======================================================
# ‚öôÔ∏è C·∫•u h√¨nh m√¥i tr∆∞·ªùng & logging
# ======================================================
load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# T·ª± ƒë·ªông t√¨m ƒë∆∞·ªùng d·∫´n database
base_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(base_dir)
DB_NAME = os.path.join(project_root, "db", "cv_job_matching.db")


# ======================================================
# üß© K·∫øt n·ªëi SQLite
# ======================================================
@contextmanager
def get_db_connection():
    conn = sqlite3.connect(DB_NAME)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()


# ======================================================
# üîß Helper
# ======================================================
def _to_int_job_id(x):
    """Chuy·ªÉn job_id v·ªÅ int an to√†n (nh·∫≠n int, '716', 'job_716'...)."""
    if isinstance(x, int):
        return x
    if isinstance(x, str):
        m = re.search(r"\d+", x)
        if m:
            try:
                return int(m.group())
            except Exception:
                return None
    return None


def _prefix_doc_with_id(doc: Document) -> Document:
    """Nh√©t JOB_ID/TITLE/URL v√†o ƒë·∫ßu page_content v√† R√öT G·ªåN content ƒë·ªÉ Gemini x·ª≠ l√Ω nhanh h∆°n."""
    mid = doc.metadata or {}
    job_id = mid.get("job_id", "")
    job_title = mid.get("job_title", "")
    job_url = mid.get("job_url", "")

    # R√∫t g·ªçn content: ch·ªâ l·∫•y 800 k√Ω t·ª± ƒë·∫ßu (ƒë·ªß cho matching)
    content = doc.page_content or ""
    if len(content) > 800:
        content = content[:800] + "..."

    header = f"JOB_ID: {job_id}\nJOB_TITLE: {job_title}\nJOB_URL: {job_url}\n-----\n"
    doc.page_content = header + content
    return doc


# ======================================================
# üîç T·∫°o c√°c th√†nh ph·∫ßn RAG (tr·∫£ v·ªÅ retriever + QA chain)
# ======================================================
def get_rag_components(model: str = "gemini-2.5-flash") -> Tuple:
    """
    Tr·∫£ v·ªÅ (retriever, qa_chain, qa_prompt).
    Sau ƒë√≥ ta s·∫Ω t·ª± g·ªçi retriever -> l·∫•y docs -> g·ªçi th·∫≥ng qa_chain v·ªõi {context: docs}.
    """
    # Use API key rotation
    from api_key_manager import get_next_api_key
    google_api_key = get_next_api_key()

    llm = ChatGoogleGenerativeAI(model=model, google_api_key=google_api_key)

    # T·∫°o retriever t·ª´ Chroma - l·∫•y 20 jobs ƒë·ªÉ Gemini rank
    vectorstore = get_vectorstore()
    retriever = vectorstore.as_retriever(search_kwargs={"k": 20})

    # Prompt t·∫°o query t√≥m t·∫Øt CV th√†nh truy v·∫•n t√¨m vi·ªác (cho history-aware retriever n·∫øu d√πng)
    contextualize_q_system_prompt = (
        "You are an assistant helping to match CV skills, aspirations, experience, and education with job postings.\n"
        "Given the match history and a combined input of skills, aspirations, experience, and education from a CV, "
        "reformulate them into a concise query for job matching.\n"
        "Extract and prioritize key keywords from skills, experience, aspirations, and education.\n"
        "Ensure the query focuses on matching CV skills and experience with job description, candidate requirements, and skills listed in job postings.\n"
        "Do NOT generate an answer, only reformulate the input into a clear and concise query."
    )
    contextualize_q_prompt = ChatPromptTemplate.from_messages([
        ("system", contextualize_q_system_prompt),
        MessagesPlaceholder("match_history"),
        ("human", "Match jobs for CV with input: {input}")
    ])
    # B·∫°n c√≥ th·ªÉ d√πng history_aware_retriever n·∫øu c·∫ßn, hi·ªán t·∫°i ta kh√¥ng d√πng n√≥ ƒë·ªÉ gi·ªØ ch·ªß ƒë·ªông context
    _ = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)

    # Prompt ch√≠nh ƒë·ªÉ RAG ƒë√°nh gi√° v√† match
    qa_prompt = ChatPromptTemplate.from_messages([
    (
        "system",
        "You are a job matching assistant. Your task is to match CV skills, aspirations, experience, and education with job postings.\n"
        "Use the provided context (job postings) to identify the top 5 most relevant jobs.\n"
        "Assign weights: 50% for skills, 30% for experience, 10% for aspirations, 10% for education.\n"
        "For matched_skills, ONLY include skills explicitly mentioned in the job's candidate_requirements, job_description, or skills list. "
        "Do NOT include skills from the CV that are not explicitly required or mentioned in the job context.\n"
        "Match experience by comparing CV experience with job description and experience required. "
        "Match aspirations with job title or description. Match education with education required.\n"
        "Provide suggestions to improve skills or gain experience relevant to the matched jobs, focusing on skills present in the CV but not matched.\n"
        "Return a JSON object with the following structure:\n"
        "{{\n"
        "  \"matched_jobs\": [{{\n"
        "      \"job_id\": int,\n"
        "      \"job_title\": str,\n"
        "      \"job_url\": str,\n"
        "      \"match_score\": float,\n"
        "      \"matched_skills\": [str],\n"
        "      \"matched_aspirations\": [str],\n"
        "      \"matched_experience\": [str],\n"
        "      \"matched_education\": [str],\n"
        "      \"why_match\": str (explain in Vietnamese why this job matches the CV, focusing on matched skills, experience, and career goals. Be specific and concise, max 100 words)\n"
        "  }}],\n"
        "  \"suggestions\": [{{\"skill_or_experience\": str, \"suggestion\": str}}]\n"
        "}}\n"
        "Ensure the response is concise, accurate, and based only on the provided context.\n"
        "Do not include any placeholder or sample data, mock examples ‚Äî only use the actual context data.\n"
        "IMPORTANT:\n"
        "- The 'job_id' MUST be taken from the 'JOB_ID:' line in the context text (not invented).\n"
        "- If a job in the context has a 'JOB_ID' that is not a number, skip it.\n"
        "- Only pick jobs that appear in the provided context.\n"
    ),
    ("system", "Context (job postings):\n{context}"),
    MessagesPlaceholder("match_history"),
    ("human", "Match jobs for CV with input: {input}")
])

    qa_chain = create_stuff_documents_chain(llm, qa_prompt, output_parser=JsonOutputParser())
    logging.info("‚úÖ StuffDocumentsChain created for Gemini.")
    return retriever, qa_chain, qa_prompt


# ======================================================
# ü§ñ H√†m Matching ch√≠nh (ƒë√£ fix vi·ªác LLM lu√¥n th·∫•y JOB_ID)
# ======================================================
async def match_cv(cv: dict, filtered_job_ids: List[int], session_id: str) -> dict:
    """
    Match m·ªôt CV v·ªõi danh s√°ch job s·ª≠ d·ª•ng:
      1) retriever ƒë·ªÉ l·∫•y top docs
      2) √©p JOB_ID/TITLE/URL v√†o page_content c·ªßa t·ª´ng doc
      3) g·ªçi th·∫≥ng qa_chain v·ªõi {context: docs}
    => Tr√°nh vi·ªác create_retrieval_chain b·ªè qua context th·ªß c√¥ng.
    """
    try:
        cv_id = cv.get("cv_id")
        if not cv_id:
            raise ValueError("CV must include cv_id")

        # ===== 1) Chu·∫©n b·ªã query =====
        query = (
            f"Skills: {json.dumps(cv.get('skills', []), ensure_ascii=False)} "
            f"Aspirations: {cv.get('aspirations', '')} "
            f"Experience: {cv.get('experience', '')} "
            f"Education: {cv.get('education', '')}"
        )
        logging.info(f"\nüß† [CV {cv_id}] Query sinh ra t·ª´ CV:\n{query}\n")

        # ===== 2) L·∫•y retriever & QA chain =====
        retriever, qa_chain, qa_prompt = get_rag_components()

        vectorstore = get_vectorstore()

        # ===== 3) Chu·∫©n b·ªã context docs =====
        logging.info(f"üîé ƒêang truy v·∫•n retriever cho CV {cv_id} ...")
        docs: List[Document] = []
        if filtered_job_ids:  # n·∫øu c√≥ filter tr∆∞·ªõc
            job_id_strs = [str(j) for j in filtered_job_ids]
            raw = vectorstore.get(where={"job_id": {"$in": job_id_strs}})
            if not raw["ids"]:
                return {
                    "cv_id": cv_id,
                    "matched_jobs": [],
                    "suggestions": [{"skill_or_experience": "N/A", "suggestion": "No jobs matched the filters"}]
                }
            for meta in raw.get("metadatas", []):
                if str(meta.get("job_id", "")).isdigit():
                    d = Document(
                        page_content=meta.get("content", ""),
                        metadata={
                            "job_id": meta.get("job_id"),
                            "job_title": meta.get("job_title"),
                            "job_url": meta.get("job_url"),
                        },
                    )
                    docs.append(_prefix_doc_with_id(d))
        else:
            # L·∫•y context t·ª´ retriever (nhanh & g·ªçn)
            context_docs = retriever.get_relevant_documents(query)
            for d in context_docs:
                docs.append(_prefix_doc_with_id(d))

        # Log s·ªë l∆∞·ª£ng jobs t√¨m ƒë∆∞·ª£c (r√∫t g·ªçn logging)
        logging.info(f"‚úÖ T√¨m ƒë∆∞·ª£c {len(docs)} jobs ph√π h·ª£p ƒë·ªÉ g·ª≠i v√†o Gemini")

        # ===== 6) G·ªçi th·∫≥ng QA chain v·ªõi context th·ªß c√¥ng =====
        result = await qa_chain.ainvoke({
            "context": docs,
            "input": query,
            "match_history": [],
        })

        # ===== 7) Parse & normalize output =====
        output = result or {}
        if not isinstance(output, dict):
            output = {}

        output["cv_id"] = cv_id
        matched = output.get("matched_jobs", []) or []
        normalized_jobs = []
        for job in matched:
            try:
                # chu·∫©n h√≥a job_id v·ªÅ int
                job_id = _to_int_job_id(job.get("job_id"))
                if job_id is None:
                    logging.warning(f"‚ö†Ô∏è Invalid job_id trong output: {job}")
                    continue
                # √©p ki·ªÉu c·∫©n th·∫≠n
                job_title = job.get("job_title") or ""
                job_url = job.get("job_url") or ""
                match_score = float(job.get("match_score", 0.0))
                matched_skills = job.get("matched_skills") or []
                matched_asp = job.get("matched_aspirations") or []
                matched_exp = job.get("matched_experience") or []
                matched_edu = job.get("matched_education") or []
                normalized_jobs.append({
                    "job_id": job_id,
                    "job_title": job_title,
                    "job_url": job_url,
                    "match_score": match_score,
                    "matched_skills": matched_skills if isinstance(matched_skills, list) else [],
                    "matched_aspirations": matched_asp if isinstance(matched_asp, list) else [],
                    "matched_experience": matched_exp if isinstance(matched_exp, list) else [],
                    "matched_education": matched_edu if isinstance(matched_edu, list) else [],
                })
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è L·ªói khi chu·∫©n h√≥a job: {e} | raw={job}")

        output["matched_jobs"] = normalized_jobs

        if not normalized_jobs:
            output.setdefault("suggestions", [])
            output["suggestions"].append({
                "skill_or_experience": "N/A",
                "suggestion": "No valid job_id returned by RAG"
            })

        logging.info(f"‚úÖ CV {cv_id} matched {len(normalized_jobs)} jobs successfully")
        return output

    except Exception as e:
        logging.error(f"‚ùå Error matching CV {cv.get('cv_id', 'unknown')}: {e}")
        return {
            "cv_id": cv.get("cv_id", "unknown"),
            "matched_jobs": [],
            "suggestions": [{"skill_or_experience": "N/A", "suggestion": f"Failed to process CV: {e}"}],
        }


# ======================================================
# üßæ Ki·ªÉm tra t√≠nh nh·∫•t qu√°n job_id gi·ªØa SQLite v√† Chroma
# ======================================================
def verify_job_id_consistency(job_id: int) -> bool:
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                SELECT job_url, job_title, work_location, skills
                FROM job_store 
                WHERE id = ?
            ''', (job_id,))
            sqlite_job = cursor.fetchone()
            if not sqlite_job:
                logging.error(f"No job found in SQLite for job_id {job_id}")
                return False

            sqlite_data = dict(sqlite_job)
            sqlite_data["job_id"] = job_id
            logging.info(f"SQLite data for job_id {job_id}: {sqlite_data}")

        vectorstore = get_vectorstore()
        chroma_docs = vectorstore.get(where={"job_id": str(job_id)})
        if not chroma_docs['ids']:
            logging.error(f"No document found in Chroma for job_id {job_id}")
            return False

        chroma_metadata = chroma_docs['metadatas'][0]
        chroma_data = {
            "job_id": chroma_metadata.get("job_id", None),
            "job_url": chroma_metadata.get("job_url", ""),
            "job_title": chroma_metadata.get("job_title", ""),
            "work_location": chroma_metadata.get("work_location", ""),
            "skills": chroma_metadata.get("skills", "")
        }
        logging.info(f"Chroma data for job_id {job_id}: {chroma_data}")

        fields_to_compare = ["job_url", "job_title", "work_location", "skills"]
        is_consistent = True
        for field in fields_to_compare:
            sqlite_value = sqlite_data[field]
            chroma_value = chroma_data[field]
            if field == "skills" and sqlite_value:
                try:
                    sqlite_value = json.dumps(json.loads(sqlite_value), ensure_ascii=False)
                except json.JSONDecodeError:
                    pass
            if sqlite_value != chroma_value:
                logging.error(f"Mismatch in {field} for job_id {job_id}: SQLite={sqlite_value}, Chroma={chroma_value}")
                is_consistent = False

        if is_consistent:
            logging.info(f"‚úÖ job_id {job_id} is consistent between SQLite and Chroma")
        else:
            logging.warning(f"‚ö†Ô∏è job_id {job_id} is NOT consistent between SQLite and Chroma")
        return is_consistent

    except Exception as e:
        logging.error(f"Error verifying job_id {job_id}: {e}")
        return False


# ======================================================
# üß™ Ki·ªÉm th·ª≠
# ======================================================
def test_job_id(job_id: int):
    print(f"ƒêang ki·ªÉm tra job_id {job_id}...")
    result = verify_job_id_consistency(job_id)
    print(f"K·∫øt qu·∫£: {'Nh·∫•t qu√°n' if result else 'Kh√¥ng nh·∫•t qu√°n'} gi·ªØa SQLite v√† Chroma")


async def test_match_cv(cv_id: int, session_id: str = "test_session"):
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('SELECT cv_info_json FROM cv_store WHERE id = ?', (cv_id,))
        cv_row = cursor.fetchone()
        if not cv_row:
            logging.error(f"No CV found for cv_id {cv_id}")
            return

        cv = json.loads(cv_row['cv_info_json'])
        cv['cv_id'] = cv_id

    result = await match_cv(cv, filtered_job_ids=None, session_id=session_id)
    print(f"K·∫øt qu·∫£ kh·ªõp CV {cv_id}:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    matched_jobs = result.get("matched_jobs", [])
    if matched_jobs:
        print("\nKi·ªÉm tra t√≠nh nh·∫•t qu√°n c·ªßa c√°c job_id trong matched_jobs:")
        for job in matched_jobs:
            jid = _to_int_job_id(job.get("job_id"))
            if jid:
                test_job_id(jid)
    else:
        print("\nKh√¥ng c√≥ c√¥ng vi·ªác n√†o ƒë∆∞·ª£c kh·ªõp ƒë·ªÉ ki·ªÉm tra.")


# ======================================================
# üöÄ Entry point
# ======================================================
if __name__ == "__main__":
    asyncio.run(test_match_cv(cv_id=4, session_id="test_session_4"))
